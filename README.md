<!-- Banner -->

<h1 align="center">ğŸ“œ Benchmarking LLMs for Translating Classical Chinese Poetry</h1>
<p align="center">
  <em>â€œThe three difficulties in translation are:adequate, fluent, and elegant.â€ â€” Yan Fu (1898)</em>  
</p>

---

<p align="center">
  <img src="https://img.shields.io/badge/Paper-EMNLP%202025-blue" />
  <img src="https://img.shields.io/badge/Language-English%20%26%20Chinese-red" />
  <img src="https://img.shields.io/badge/License-MIT-green" />
  <img src="https://img.shields.io/badge/Poetry-Tang%20%7C%20Song%20%7C%20Yuan-yellow" />
</p>

---

## ğŸŒ¸ Overview

This repository introduces **PoetMT**, the first benchmark for **translating Classical Chinese Poetry into English**.  
We evaluate **Large Language Models (LLMs)** on three dimensions:

- **Adequacy (ä¿¡)** â†’ Accuracy of meaning & cultural faithfulness  
- **Fluency (è¾¾)** â†’ Smoothness of rhythm & structural alignment  
- **Elegance (é›…)** â†’ Poetic beauty & aesthetic depth  

We also propose **RAT (Retrieval-Augmented Translation)**, which integrates historical and literary knowledge to improve performance.

---

## âœ¨ Key Features

âœ… **PoetMT Benchmark** â€” All poems from **Tang, Song, Yuan** dynasties  
âœ… **Three-Dimensional Evaluation** â€” GPT-4-based metrics: *Beauty of Sound (BS)*, *Beauty of Form (BF)*, *Beauty of Meaning (BM)*  
âœ… **RAT Method** â€” retrieval-augmented framework leveraging a **Classical Poetry Knowledge Base**  
âœ… **Superior Results** â€” significantly closer to human evaluation than standard LLM baselines  

---

## ğŸ“‚ Dataset

- **PoetMT Dataset**
  - Human expert translations  
  - Supports **sentence-level adequacy** & **discourse-level elegance** tasks  

- **Knowledge Base**
  - 30,000+ classical poems with:  
    - Dynasty & historical background  
    - Modern Chinese translations  
    - Author introductions  
    - Poetic structure & analysis  

---

## ğŸ“Š Results

| Method       | COMET â†‘ | BLEURT â†‘ | LLM-BM â†‘ | LLM-BS â†‘ | LLM-BF â†‘ | LLM-Avg â†‘ |
|--------------|---------|----------|----------|----------|----------|-----------|
| GPT-4        | 60.3    | 43.0     | 4.0      | 3.7      | 3.6      | 3.8       |
| ChatGPT      | 61.1    | 42.4     | 3.3      | 3.2      | 2.9      | 3.1       |
| **RAT (Ours)** | **62.7** | **43.9** | **4.1** | **3.9** | **3.9** | **4.0**   |

ğŸ“Œ **RAT outperforms all baselines**, especially in **Elegance (BM)**, aligning closely with human evaluation.

---

## ğŸ”® Future Directions

- ğŸŒ **Cross-cultural generation** â€” extend to other literary traditions  
- ğŸ¨ **Multimodal integration** â€” enrich translation with images & audio context  
- ğŸ“ **Expanded evaluation** â€” design broader aesthetic and cultural metrics  

---

## ğŸ“œ Citation

If you use this project, please cite our EMNLP 2025 paper:

```bibtex
@inproceedings{chen2025benchmarking,
  title={Benchmarking LLMs for Translating Classical Chinese Poetry: Evaluating Adequacy, Fluency, and Elegance},
  author={Chen, Andong and Lou, Lianzhang and Chen, Kehai and Bai, Xuefeng and Xiang, Yang and Yang, Muyun and Zhao, Tiejun and Zhang, Min},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  year={2025}
}
